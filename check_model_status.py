#!/usr/bin/env python3
"""
Check the status of the portfolio volatility model
"""

import os
import sys
from datetime import datetime
import pandas as pd

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def check_model_status():
    """Check the current status of the volatility models"""
    
    print("ðŸ” MODEL STATUS CHECK")
    print("=" * 40)
    
    # Check if trained model exists
    model_path = "model/portfolio_volatility_model.pkl"
    
    if os.path.exists(model_path):
        # Get model file info
        stat_info = os.stat(model_path)
        file_size = stat_info.st_size / 1024  # KB
        mod_time = datetime.fromtimestamp(stat_info.st_mtime)
        
        print(f"âœ… Trained Model: FOUND")
        print(f"   ðŸ“ Path: {model_path}")
        print(f"   ðŸ“ Size: {file_size:.1f} KB")
        print(f"   ðŸ•’ Last Modified: {mod_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # Test loading the model
        try:
            from utils.simple_model_trainer import PortfolioVolatilityTrainer
            trainer = PortfolioVolatilityTrainer()
            trainer.load_model(model_path)
            print(f"   âœ… Model loads successfully")
            
            # Test prediction
            test_portfolio = pd.DataFrame({
                'Ticker': ['SPY'], 
                'Weight': [1.0]
            })
            
            prediction = trainer.predict_volatility(test_portfolio)
            print(f"   ðŸŽ¯ Test Prediction: {prediction['interpretation']['annual_volatility_pct']}")
            
        except Exception as e:
            print(f"   âŒ Model loading failed: {e}")
    
    else:
        print(f"âŒ Trained Model: NOT FOUND")
        print(f"   ðŸ“ Expected Path: {model_path}")
        print(f"   ðŸ’¡ Run: python train_model.py")
    
    print()
    
    # Check enhanced model components
    print(f"ðŸš€ Enhanced Model Components:")
    
    enhanced_files = [
        "utils/enhanced_volatility_estimator.py",
        "utils/volatility_model_enhancer.py"
    ]
    
    for file_path in enhanced_files:
        if os.path.exists(file_path):
            print(f"   âœ… {os.path.basename(file_path)}")
        else:
            print(f"   âŒ {os.path.basename(file_path)} - MISSING")
    
    # Test enhanced model
    try:
        from utils.volatility_model_enhancer import VolatilityModelEnhancer
        enhancer = VolatilityModelEnhancer()
        print(f"   âœ… Enhanced model initializes successfully")
        
        # Test with known asset
        test_result = enhancer.get_enhanced_asset_volatility("AAPL", use_apis=False)
        print(f"   ðŸŽ¯ Test Asset (AAPL): {test_result['volatility']:.1%} ({test_result['confidence']} confidence)")
        
    except Exception as e:
        print(f"   âŒ Enhanced model failed: {e}")
    
    print()
    
    # Check API integration
    print(f"ðŸ”Œ API Integration:")
    
    try:
        from utils.model_predict import predict_volatility
        
        test_portfolio = pd.DataFrame({
            'Ticker': ['AAPL', 'VTI'], 
            'Weight': [0.6, 0.4]
        })
        
        result = predict_volatility(test_portfolio, forecast_days=20)
        
        print(f"   âœ… Main API working")
        print(f"   ðŸŽ¯ Test Portfolio Volatility: {result['predicted_volatility'][0]:.1%}")
        print(f"   ðŸ¤– Model Type: {result['model_type']}")
        
        if 'enhancement_data' in result:
            coverage = result['enhancement_data']['coverage_analysis']['coverage_by_count']
            confidence = result['enhancement_data']['overall_confidence']
            print(f"   ðŸ“Š Asset Coverage: {coverage:.1%}")
            print(f"   ðŸŽ¯ Confidence: {confidence}")
        
    except Exception as e:
        print(f"   âŒ API integration failed: {e}")
    
    print()
    
    # Check data files
    print(f"ðŸ“Š Sample Data Files:")
    
    data_files = [
        "data/sample_portfolio.csv",
        "data/sample_bonds.csv",
        "data/sample_portfolio_btc_1.csv"
    ]
    
    for file_path in data_files:
        if os.path.exists(file_path):
            try:
                df = pd.read_csv(file_path)
                print(f"   âœ… {os.path.basename(file_path)} ({len(df)} rows)")
            except:
                print(f"   âš ï¸ {os.path.basename(file_path)} (corrupted)")
        else:
            print(f"   âŒ {os.path.basename(file_path)} - MISSING")
    
    print()
    
    # Recommendations
    print(f"ðŸŽ¯ RECOMMENDATIONS:")
    
    if not os.path.exists(model_path):
        print(f"   1. Train the base model: python train_model.py")
    else:
        mod_time = datetime.fromtimestamp(os.stat(model_path).st_mtime)
        days_old = (datetime.now() - mod_time).days
        
        if days_old > 30:
            print(f"   1. Consider retraining (model is {days_old} days old): python retrain_model.py")
        else:
            print(f"   1. âœ… Model is recent ({days_old} days old)")
    
    print(f"   2. Test with your portfolios using the enhanced API")
    print(f"   3. Consider adding API keys for better unknown asset coverage")
    
    # API key status
    try:
        from utils.enhanced_volatility_estimator import EnhancedVolatilityEstimator
        estimator = EnhancedVolatilityEstimator()
        
        if estimator.alpha_vantage_key:
            print(f"   4. âœ… Alpha Vantage API key configured")
        else:
            print(f"   4. ðŸ”‘ Add Alpha Vantage API key for enhanced accuracy")
        
        if estimator.fmp_key:
            print(f"   5. âœ… Financial Modeling Prep API key configured")
        else:
            print(f"   5. ðŸ”‘ Add Financial Modeling Prep API key for enhanced accuracy")
    
    except:
        pass

if __name__ == "__main__":
    check_model_status()